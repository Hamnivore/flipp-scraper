{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%b %d, %Y\")\n",
    "\n",
    "# Set up directories\n",
    "unlabeled_dir = Path('flyer_data')\n",
    "labeled_dir = Path('labeled_flyer_data')\n",
    "labeled_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def log_info(message):\n",
    "    \"\"\"Log information to a file.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open('batch_processing_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {message}\\n\")\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"\"\"\n",
    "Your goal is to help shoppers find the best deals. You will be given an image of a product ad and its price.\n",
    "Calculate the price per unit and recommend what the user should do with the item. If at all possible,\n",
    "get the unit as a weight or volume. Especially for food items, this is usually the best way to compare deals.\n",
    "\"\"\"\n",
    "\n",
    "def prepare_deal_input(item, flyer_filename):\n",
    "    price = float(item['price'])\n",
    "    return {\n",
    "        \"custom_id\": f\"{flyer_filename}|{item['id']}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"Today is {current_date}. Evaluate {item['name']} priced at ${price:.2f}.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": item['cutout_image_url']}}\n",
    "                ]}\n",
    "            ],\n",
    "            \"max_tokens\": 100,\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"deal_schema\",\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"price_per_unit\": {\n",
    "                                \"description\": \"Formatted as $X.XX/unit, where unit is one of: lb, oz, g, kg, gal, qt, pt, fl oz, ea.\",\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            \"user_recommendation\": {\n",
    "                                \"description\": \"Tell the user what to do with this item so they can save money. For example, 'Buy bulk and fill your freezer!', 'Wait for a better deal', 'Buy if you need it soon', 'This deal is so good you should buy and resell it!'\",\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            \"deal_score\": {\n",
    "                                \"description\": \"A score from 1 to 5 indicating how good the deal is. 1 is worse than average, 2 is around the expected price, and 5 is that rare smoking unicorn deal.\",\n",
    "                                \"type\": \"integer\",\n",
    "                                \"minimum\": 1,\n",
    "                                \"maximum\": 5\n",
    "                            },\n",
    "                            \"meal_prep_score\": {\n",
    "                                \"description\": \"A score from 1 to 5 indicating how good the deal is for meal-prepping. 1 is anything that isn't a food item, 2 is food that isn't very nutritious (soft drinks, candy, chips), 3 is high quality sweets (pastries, ice cream, etc.), 4 is good canned or frozen food, and 5 is fresh produce, meat, dairy, or other high quality food.\",\n",
    "                                \"type\": \"integer\",\n",
    "                                \"minimum\": 1,\n",
    "                                \"maximum\": 5\n",
    "                            },\n",
    "                            \"in_season\": {\n",
    "                                \"description\": \"true if the item is in season, false otherwise.\",\n",
    "                                \"type\": \"boolean\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 63 unlabeled flyers\n",
      "Prepared 4360 items for batch processing\n",
      "Estimated total tokens: 39420013\n",
      "  - Text tokens: 2360013\n",
      "  - Image tokens: 37060000\n",
      "Number of batches: 22\n",
      "Estimated total cost: $5.87\n",
      "Flyers to process saved: flyers_to_process.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load flyer data, prepare batch input, split into batches, and estimate cost\n",
    "\n",
    "def estimate_tokens(text, has_image=True):\n",
    "    \"\"\"Estimate the number of tokens in the given text, plus image tokens if applicable.\"\"\"\n",
    "    text_tokens = len(text) // 4  # Using the heuristic that 1 token ~= 4 chars in English\n",
    "    image_tokens = 8500 if has_image else 0  # Add 8500 tokens for each image\n",
    "    return text_tokens, image_tokens\n",
    "\n",
    "def estimate_cost(text_tokens, image_tokens, max_output_tokens=100):\n",
    "    \"\"\"Estimate the cost based on input tokens, image tokens, and output tokens.\"\"\"\n",
    "    image_cost = (image_tokens / 1_000_000) * 0.15\n",
    "    input_text_cost = (text_tokens / 1_000_000) * 0.075\n",
    "    output_cost = (max_output_tokens / 1_000_000) * 0.300\n",
    "    return image_cost + input_text_cost + output_cost\n",
    "\n",
    "batch_input = []\n",
    "flyers_to_process = []\n",
    "total_text_tokens = 0\n",
    "total_image_tokens = 0\n",
    "total_cost = 0\n",
    "MAX_TOKENS_PER_BATCH = 1_800_000  # We'll keep this the same for now\n",
    "batches = []\n",
    "current_batch = []\n",
    "current_batch_tokens = 0\n",
    "\n",
    "for flyer_file in unlabeled_dir.glob('*.json'):\n",
    "    labeled_file = labeled_dir / flyer_file.name\n",
    "    if not labeled_file.exists():\n",
    "        with open(flyer_file, 'r') as f:\n",
    "            flyer_data = json.load(f)\n",
    "        \n",
    "        flyers_to_process.append(flyer_file.name)\n",
    "        \n",
    "        for item in flyer_data['items']:\n",
    "            input_data = prepare_deal_input(item, flyer_file.name)\n",
    "            item_text = json.dumps(input_data)\n",
    "            text_tokens, image_tokens = estimate_tokens(item_text)\n",
    "            item_tokens = text_tokens + image_tokens\n",
    "            item_cost = estimate_cost(text_tokens, image_tokens)\n",
    "            \n",
    "            if current_batch_tokens + item_tokens > MAX_TOKENS_PER_BATCH:\n",
    "                batches.append(current_batch)\n",
    "                current_batch = []\n",
    "                current_batch_tokens = 0\n",
    "            \n",
    "            current_batch.append(input_data)\n",
    "            current_batch_tokens += item_tokens\n",
    "            total_text_tokens += text_tokens\n",
    "            total_image_tokens += image_tokens\n",
    "            total_cost += item_cost\n",
    "\n",
    "if current_batch:\n",
    "    batches.append(current_batch)\n",
    "\n",
    "if not flyers_to_process:\n",
    "    log_info(\"No new flyers to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "total_tokens = total_text_tokens + total_image_tokens\n",
    "\n",
    "log_info(f\"Loaded {len(flyers_to_process)} unlabeled flyers\")\n",
    "log_info(f\"Prepared {sum(len(batch) for batch in batches)} items for batch processing\")\n",
    "log_info(f\"Estimated total tokens: {total_tokens}\")\n",
    "log_info(f\"  - Text tokens: {total_text_tokens}\")\n",
    "log_info(f\"  - Image tokens: {total_image_tokens}\")\n",
    "log_info(f\"Number of batches: {len(batches)}\")\n",
    "log_info(f\"Estimated total cost: ${total_cost:.2f}\")\n",
    "\n",
    "# Save flyers_to_process for later use\n",
    "with open('flyers_to_process.json', 'w') as f:\n",
    "    json.dump(flyers_to_process, f)\n",
    "\n",
    "log_info(\"Flyers to process saved: flyers_to_process.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch input file 0 with ID: file-v26wxjqgwUiHgWz3upPO0Hod\n",
      "Created batch 0 with ID: batch_6719c9387b048190ac0cb5f6cb9da2e2\n",
      "Uploaded batch input file 1 with ID: file-t4HAisEWSlCh5d9rswtJMY5q\n",
      "Created batch 1 with ID: batch_6719c939b82c8190bc10920347fd3769\n",
      "Uploaded batch input file 2 with ID: file-fh2BmLNHlgGm6f50Mxl2ovov\n",
      "Created batch 2 with ID: batch_6719c93aa69481908c4c172954c2c1bb\n",
      "Uploaded batch input file 3 with ID: file-7hrclOIFEMinZtcTx1kYMBKd\n",
      "Created batch 3 with ID: batch_6719c93b8e34819089aa296ffa09d8b0\n",
      "Uploaded batch input file 4 with ID: file-Ql7IMxE4EAiDcmR8DDDn6Ehm\n",
      "Created batch 4 with ID: batch_6719c93c998c8190bfe6869bfbbe7953\n",
      "Uploaded batch input file 5 with ID: file-5KRfIFUFz3ThN8iLB20QnzD1\n",
      "Created batch 5 with ID: batch_6719c93da59081908e9d03fac0c26285\n",
      "Uploaded batch input file 6 with ID: file-sC1xisaUdh6Fk8bZd1vQNV3p\n",
      "Created batch 6 with ID: batch_6719c93e82d481909b481e88b10a93fe\n",
      "Uploaded batch input file 7 with ID: file-pXSSHDHFLmO82YpnK3eQYRVu\n",
      "Created batch 7 with ID: batch_6719c93fb97481909855ae61cd9909ff\n",
      "Uploaded batch input file 8 with ID: file-E64W8IXgBwUT8pe04wg7LKnn\n",
      "Created batch 8 with ID: batch_6719c940a94c8190ae9b1509e8a90ca7\n",
      "Uploaded batch input file 9 with ID: file-eI6CmPTocuWgXFk2owC3jrCN\n",
      "Created batch 9 with ID: batch_6719c9419544819082119760650c1057\n",
      "Uploaded batch input file 10 with ID: file-g6xj9Ef7gVPU3ZzeLgb6qCUY\n",
      "Created batch 10 with ID: batch_6719c942601081908725997b99fd11ad\n",
      "Uploaded batch input file 11 with ID: file-EIApmXhkUZo7fGXh1WWDOHZs\n",
      "Created batch 11 with ID: batch_6719c94336248190adc0b94ca6c03931\n",
      "Uploaded batch input file 12 with ID: file-mVLY8OKPcQZTODMqepGOT3z1\n",
      "Created batch 12 with ID: batch_6719c94417dc8190b637961a83da5ceb\n",
      "Uploaded batch input file 13 with ID: file-AzFBZSTjC79pbyNPQrGD1fVa\n",
      "Created batch 13 with ID: batch_6719c944cd5881909959420746d9327d\n",
      "Uploaded batch input file 14 with ID: file-vXVe3yPXrDgB2Icy4KkUCZqP\n",
      "Created batch 14 with ID: batch_6719c945b8a08190b6f056e95fac126f\n",
      "Uploaded batch input file 15 with ID: file-AVM5lxp4fwXIpBbJDaxH4SRt\n",
      "Created batch 15 with ID: batch_6719c946a2dc81909f7360e0ee77dac4\n",
      "Uploaded batch input file 16 with ID: file-m4e7tDffnwA0T4biNg3JvIp9\n",
      "Created batch 16 with ID: batch_6719c947733c8190af53e01c6696a99c\n",
      "Uploaded batch input file 17 with ID: file-U4yEWKduD6O3PkGVKRCwGJCS\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 16\u001b[0m\n\u001b[0;32m      9\u001b[0m batch_input_file \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     10\u001b[0m     file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(batch_filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     11\u001b[0m     purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m log_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploaded batch input file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_input_file\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_file_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_input_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompletion_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m24h\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCheap deals analysis batch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m batch_ids\u001b[38;5;241m.\u001b[39mappend(batch\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m     26\u001b[0m log_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\openai\\resources\\batches.py:96\u001b[0m, in \u001b[0;36mBatches.create\u001b[1;34m(self, completion_window, endpoint, input_file_id, metadata, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m     63\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Batch:\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Creates and executes a batch from an uploaded file of requests\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/batches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompletion_window\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletion_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mendpoint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_file_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_file_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\openai\\_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1276\u001b[0m     )\n\u001b[1;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\openai\\_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\openai\\_base_client.py:990\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 990\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    996\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\samue\\Programming\\Misc\\flipp-scraper\\venv\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python38\\lib\\ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mC:\\Python38\\lib\\ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_ids = []\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    batch_filename = f'batch_input_{i}.jsonl'\n",
    "    with open(batch_filename, 'w') as f:\n",
    "        for item in batch:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    \n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(batch_filename, \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "\n",
    "    log_info(f\"Uploaded batch input file {i} with ID: {batch_input_file.id}\")\n",
    "\n",
    "    batch = client.batches.create(\n",
    "        input_file_id=batch_input_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Cheap deals analysis batch {i}\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    batch_ids.append(batch.id)\n",
    "    log_info(f\"Created batch {i} with ID: {batch.id}\")\n",
    "\n",
    "# Save batch IDs for later use\n",
    "with open('batch_ids.json', 'w') as f:\n",
    "    json.dump(batch_ids, f)\n",
    "\n",
    "log_info(f\"Created {len(batch_ids)} batches. Batch IDs saved to batch_ids.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch group 1 of 4\n",
      "Batch batch_6719c9387b048190ac0cb5f6cb9da2e2 completed and processed.\n",
      "Batch batch_6719c939b82c8190bc10920347fd3769 completed and processed.\n",
      "Batch batch_6719c93c998c8190bfe6869bfbbe7953 completed and processed.\n",
      "Waiting for 2 batches to complete...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from math import ceil\n",
    "\n",
    "MAX_CONCURRENT_BATCHES = 5  # Adjust this based on the token limit and batch sizes\n",
    "BATCH_CHECK_INTERVAL = 60  # Check batch status every 60 seconds\n",
    "\n",
    "def process_batch_group(batch_ids, start_index, end_index):\n",
    "    group_results = []\n",
    "    active_batches = batch_ids[start_index:end_index]\n",
    "    \n",
    "    while active_batches:\n",
    "        for batch_id in active_batches[:]:\n",
    "            batch_status = client.batches.retrieve(batch_id)\n",
    "            \n",
    "            if batch_status.status == \"completed\":\n",
    "                output_file_content = client.files.content(batch_status.output_file_id)\n",
    "                output_text = output_file_content.read().decode('utf-8')\n",
    "                batch_results = [json.loads(line) for line in output_text.strip().split('\\n')]\n",
    "                group_results.extend(batch_results)\n",
    "                active_batches.remove(batch_id)\n",
    "                log_info(f\"Batch {batch_id} completed and processed.\")\n",
    "            elif batch_status.status == \"failed\":\n",
    "                log_info(f\"Batch {batch_id} failed. Error: {batch_status.errors}\")\n",
    "                active_batches.remove(batch_id)\n",
    "        \n",
    "        if active_batches:\n",
    "            log_info(f\"Waiting for {len(active_batches)} batches to complete...\")\n",
    "            time.sleep(BATCH_CHECK_INTERVAL)\n",
    "    \n",
    "    return group_results\n",
    "\n",
    "# Load batch IDs and flyers to process\n",
    "with open('batch_ids.json', 'r') as f:\n",
    "    batch_ids = json.load(f)\n",
    "\n",
    "with open('flyers_to_process.json', 'r') as f:\n",
    "    flyers_to_process = json.load(f)\n",
    "\n",
    "all_results = []\n",
    "num_groups = ceil(len(batch_ids) / MAX_CONCURRENT_BATCHES)\n",
    "\n",
    "for i in range(num_groups):\n",
    "    start_index = i * MAX_CONCURRENT_BATCHES\n",
    "    end_index = min((i + 1) * MAX_CONCURRENT_BATCHES, len(batch_ids))\n",
    "    \n",
    "    log_info(f\"Processing batch group {i+1} of {num_groups}\")\n",
    "    group_results = process_batch_group(batch_ids, start_index, end_index)\n",
    "    all_results.extend(group_results)\n",
    "    \n",
    "    log_info(f\"Completed batch group {i+1}. Total results so far: {len(all_results)}\")\n",
    "\n",
    "# Group results by flyer\n",
    "flyer_results = {}\n",
    "for result in all_results:\n",
    "    flyer_filename, item_id = result['custom_id'].split('|')\n",
    "    if flyer_filename not in flyer_results:\n",
    "        flyer_results[flyer_filename] = []\n",
    "    flyer_results[flyer_filename].append((item_id, json.loads(result['response']['body'])))\n",
    "\n",
    "# Update flyers with results and save labeled versions\n",
    "for flyer_filename in flyers_to_process:\n",
    "    with open(unlabeled_dir / flyer_filename, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    \n",
    "    for item in flyer_data['items']:\n",
    "        item_results = next((r for r in flyer_results[flyer_filename] if r[0] == str(item['id'])), None)\n",
    "        if item_results:\n",
    "            item['deal_analysis'] = item_results[1]\n",
    "    \n",
    "    # Save labeled flyer\n",
    "    labeled_file = labeled_dir / flyer_filename\n",
    "    with open(labeled_file, 'w') as f:\n",
    "        json.dump(flyer_data, f, indent=2)\n",
    "\n",
    "log_info(f\"Processed {len(all_results)} results and saved labeled flyers to {labeled_dir}\")\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('batch_ids.json')\n",
    "os.remove('flyers_to_process.json')\n",
    "for i in range(len(batch_ids)):\n",
    "    os.remove(f'batch_input_{i}.jsonl')\n",
    "log_info(\"Cleaned up temporary files\")\n",
    "\n",
    "# Display sample of labeled items\n",
    "labeled_flyers = list(labeled_dir.glob('*.json'))\n",
    "if labeled_flyers:\n",
    "    print(\"\\nSample of labeled items:\")\n",
    "    sample_flyer = labeled_flyers[0]\n",
    "    print(f\"Flyer: {sample_flyer.name}\")\n",
    "    with open(sample_flyer, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    for item in flyer_data['items'][:5]:\n",
    "        print(json.dumps(item, indent=2))\n",
    "        print()\n",
    "else:\n",
    "    print(\"No labeled flyers found. Please check if the processing completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No active batches found. Please run the previous cells to create new batches.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('batch_ids.json'):\n",
    "    with open('batch_ids.json', 'r') as f:\n",
    "        batch_ids = json.load(f)\n",
    "    \n",
    "    for i, batch_id in enumerate(batch_ids):\n",
    "        batch_status = client.batches.retrieve(batch_id)\n",
    "        log_info(f\"Batch {i} status: {batch_status.status}\")\n",
    "        log_info(f\"Completed requests: {batch_status.request_counts.completed}\")\n",
    "        log_info(f\"Failed requests: {batch_status.request_counts.failed}\")\n",
    "        \n",
    "        if batch_status.status == \"failed\":\n",
    "            log_info(f\"Batch {i} failed. Retrieving error information...\")\n",
    "            \n",
    "            if batch_status.error_file_id:\n",
    "                error_file_content = client.files.content(batch_status.error_file_id)\n",
    "                error_text = error_file_content.read().decode('utf-8')\n",
    "                log_info(\"Error details:\")\n",
    "                print(error_text)\n",
    "            else:\n",
    "                log_info(\"No detailed error information available.\")\n",
    "            \n",
    "            if batch_status.errors:\n",
    "                log_info(\"Batch level errors:\")\n",
    "                for error in batch_status.errors:\n",
    "                    if isinstance(error, tuple):\n",
    "                        print(f\"Error: {error}\")\n",
    "                    elif hasattr(error, 'message'):\n",
    "                        print(f\"Error: {error.message}\")\n",
    "                    else:\n",
    "                        print(f\"Error: {error}\")\n",
    "        print()  # Add a blank line between batch status reports\n",
    "else:\n",
    "    log_info(\"No active batches found. Please run the previous cells to create new batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cancelling batch batch_6719c9387b048190ac0cb5f6cb9da2e2: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c939b82c8190bc10920347fd3769: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c93aa69481908c4c172954c2c1bb: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Cancelled batch batch_6719c93b8e34819089aa296ffa09d8b0\n",
      "Error cancelling batch batch_6719c93c998c8190bfe6869bfbbe7953: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c93da59081908e9d03fac0c26285: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c93e82d481909b481e88b10a93fe: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Cancelled batch batch_6719c93fb97481909855ae61cd9909ff\n",
      "Error cancelling batch batch_6719c940a94c8190ae9b1509e8a90ca7: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c9419544819082119760650c1057: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c942601081908725997b99fd11ad: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c94336248190adc0b94ca6c03931: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'failed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c94417dc8190b637961a83da5ceb: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'failed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c944cd5881909959420746d9327d: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'failed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c945b8a08190b6f056e95fac126f: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'failed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c946a2dc81909f7360e0ee77dac4: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'failed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error cancelling batch batch_6719c947733c8190af53e01c6696a99c: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'failed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Cleaned up temporary files\n"
     ]
    }
   ],
   "source": [
    "# Cell to cancel the in-progress batch\n",
    "import json\n",
    "with open('batch_ids.json', 'r') as f:\n",
    "    batch_ids = json.load(f)\n",
    "\n",
    "for batch_id in batch_ids:\n",
    "    try:\n",
    "        client.batches.cancel(batch_id)\n",
    "        log_info(f\"Cancelled batch {batch_id}\")\n",
    "    except Exception as e:\n",
    "        log_info(f\"Error cancelling batch {batch_id}: {str(e)}\")\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('batch_ids.json')\n",
    "os.remove('flyers_to_process.json')\n",
    "for i in range(len(batch_ids)):\n",
    "    os.remove(f'batch_input_{i}.jsonl')\n",
    "log_info(\"Cleaned up temporary files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('batch_ids.json') or not os.path.exists('flyers_to_process.json'):\n",
    "    log_info(\"No active batches or flyers to process found. Please run the previous cells to create new batches.\")\n",
    "    exit()\n",
    "\n",
    "with open('batch_ids.json', 'r') as f:\n",
    "    batch_ids = json.load(f)\n",
    "\n",
    "with open('flyers_to_process.json', 'r') as f:\n",
    "    flyers_to_process = json.load(f)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for batch_id in batch_ids:\n",
    "    batch_status = client.batches.retrieve(batch_id)\n",
    "\n",
    "    if batch_status.status == \"completed\":\n",
    "        output_file_content = client.files.content(batch_status.output_file_id)\n",
    "        output_text = output_file_content.read().decode('utf-8')\n",
    "        \n",
    "        # Process the output\n",
    "        batch_results = [json.loads(line) for line in output_text.strip().split('\\n')]\n",
    "        all_results.extend(batch_results)\n",
    "    else:\n",
    "        log_info(f\"Batch {batch_id} is not yet completed. Please check again later.\")\n",
    "        exit()\n",
    "\n",
    "# Group results by flyer\n",
    "flyer_results = {}\n",
    "for result in all_results:\n",
    "    flyer_filename, item_id = result['custom_id'].split('|')\n",
    "    if flyer_filename not in flyer_results:\n",
    "        flyer_results[flyer_filename] = []\n",
    "    flyer_results[flyer_filename].append((item_id, json.loads(result['response']['body'])))\n",
    "\n",
    "# Update flyers with results and save labeled versions\n",
    "for flyer_filename in flyers_to_process:\n",
    "    with open(unlabeled_dir / flyer_filename, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    \n",
    "    for item in flyer_data['items']:\n",
    "        item_results = next((r for r in flyer_results[flyer_filename] if r[0] == str(item['id'])), None)\n",
    "        if item_results:\n",
    "            item['deal_analysis'] = item_results[1]\n",
    "    \n",
    "    # Save labeled flyer\n",
    "    labeled_file = labeled_dir / flyer_filename\n",
    "    with open(labeled_file, 'w') as f:\n",
    "        json.dump(flyer_data, f, indent=2)\n",
    "\n",
    "log_info(f\"Processed {len(all_results)} results and saved labeled flyers to {labeled_dir}\")\n",
    "\n",
    "# Clean up temporary files\n",
    "os.remove('batch_ids.json')\n",
    "os.remove('flyers_to_process.json')\n",
    "for i in range(len(batch_ids)):\n",
    "    os.remove(f'batch_input_{i}.jsonl')\n",
    "log_info(\"Cleaned up temporary files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_flyers = list(labeled_dir.glob('*.json'))\n",
    "if labeled_flyers:\n",
    "    print(\"\\nSample of labeled items:\")\n",
    "    sample_flyer = labeled_flyers[0]\n",
    "    print(f\"Flyer: {sample_flyer.name}\")\n",
    "    with open(sample_flyer, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    for item in flyer_data['items'][:5]:\n",
    "        print(json.dumps(item, indent=2))\n",
    "        print()\n",
    "else:\n",
    "    print(\"No labeled flyers found. Please run the processing cell when the batch is completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 199 results from batch batch_6719c33a60a481908a4b639aabcc9ea2\n",
      "Retrieved 199 results from batch batch_6719c33b97d08190baba5c2198e6d341\n",
      "Retrieved 199 results from batch batch_6719c33d6be881908e54e8f15f1d24d2\n",
      "Retrieved 199 results from batch batch_6719c34183d881909d84f283a4ea3e55\n",
      "Retrieved 198 results from batch batch_6719c348e3488190b99ee5a11a5452f0\n",
      "\n",
      "Sample of completed results:\n",
      "\n",
      "Custom ID: Big 5 Sporting Goods_Weekly Ad_20241021-20241023_6879293.json|884578110\n",
      "Response: {\n",
      "  \"id\": \"chatcmpl-ALj6THNRN2SY7tNGUPM36mw62sicL\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1729741629,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\\"price_per_unit\\\":\\\"$15.99/ea\\\",\\\"user_recommendation\\\":\\\"Buy if you need it soon\\\",\\\"deal_score\\\":3,\\\"meal_prep_score\\\":1,\\\"in_season\\\":false}\",\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8905,\n",
      "    \"completion_tokens\": 42,\n",
      "    \"total_tokens\": 8947,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_8bfc6a7dc2\"\n",
      "}\n",
      "\n",
      "Custom ID: Big 5 Sporting Goods_Weekly Ad_20241021-20241023_6879293.json|884578111\n",
      "Response: {\n",
      "  \"id\": \"chatcmpl-ALj6TzTrEGjH0CgAJHopKTiqSO8J8\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1729741629,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\\"price_per_unit\\\":\\\"$15.99/ea\\\",\\\"user_recommendation\\\":\\\"Buy if you need a soccer ball soon, as prices can fluctuate with demand.\\\",\\\"deal_score\\\":3,\\\"meal_prep_score\\\":1,\\\"in_season\\\":false}\",\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8905,\n",
      "    \"completion_tokens\": 51,\n",
      "    \"total_tokens\": 8956,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_7693ae462b\"\n",
      "}\n",
      "\n",
      "Custom ID: Big 5 Sporting Goods_Weekly Ad_20241021-20241023_6879293.json|884578112\n",
      "Response: {\n",
      "  \"id\": \"chatcmpl-ALj6SPm931VCtTVqjl0NHPvvAM5Y8\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1729741628,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\\"price_per_unit\\\":\\\"$34.99/ea\\\",\\\"user_recommendation\\\":\\\"This glove is a good price if you need one for the season, consider buying it now!\\\",\\\"deal_score\\\":4,\\\"meal_prep_score\\\":1,\\\"in_season\\\":true}\",\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8911,\n",
      "    \"completion_tokens\": 55,\n",
      "    \"total_tokens\": 8966,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_7693ae462b\"\n",
      "}\n",
      "\n",
      "Custom ID: Big 5 Sporting Goods_Weekly Ad_20241021-20241023_6879293.json|882520540\n",
      "Response: {\n",
      "  \"id\": \"chatcmpl-ALj6Trn0JotiK5XSIxLcnzmzdCaq0\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1729741629,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\\"price_per_unit\\\":\\\"$3.17/ea\\\",\\\"user_recommendation\\\":\\\"Buy if you need new socks soon!\\\",\\\"deal_score\\\":3,\\\"meal_prep_score\\\":1,\\\"in_season\\\":false}\",\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8909,\n",
      "    \"completion_tokens\": 44,\n",
      "    \"total_tokens\": 8953,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_7693ae462b\"\n",
      "}\n",
      "\n",
      "Custom ID: Big 5 Sporting Goods_Weekly Ad_20241021-20241023_6879293.json|884578102\n",
      "Response: {\n",
      "  \"id\": \"chatcmpl-ALj6TNW9uo6j2y7Nr10Ru2EJalyJT\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1729741629,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"{\\\"price_per_unit\\\":\\\"$0.59/oz\\\",\\\"user_recommendation\\\":\\\"Buy if you need it soon, but consider other options for better value.\\\",\\\"deal_score\\\":3,\\\"meal_prep_score\\\":1,\\\"in_season\\\":false}\",\n",
      "        \"refusal\": null\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8909,\n",
      "    \"completion_tokens\": 50,\n",
      "    \"total_tokens\": 8959,\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_7693ae462b\"\n",
      "}\n",
      "Total results retrieved: 994\n",
      "All results saved to completed_results.json\n"
     ]
    }
   ],
   "source": [
    "# Cell to retrieve and display results of completed batches\n",
    "\n",
    "def get_completed_batch_results(batch_id):\n",
    "    batch_status = client.batches.retrieve(batch_id)\n",
    "    if batch_status.status == \"completed\":\n",
    "        output_file_content = client.files.content(batch_status.output_file_id)\n",
    "        output_text = output_file_content.read().decode('utf-8')\n",
    "        return [json.loads(line) for line in output_text.strip().split('\\n')]\n",
    "    return []\n",
    "\n",
    "# List of batch IDs that were completed\n",
    "completed_batch_ids = [\n",
    "    \"batch_6719c33a60a481908a4b639aabcc9ea2\",\n",
    "    \"batch_6719c33b97d08190baba5c2198e6d341\",\n",
    "    \"batch_6719c33d6be881908e54e8f15f1d24d2\",\n",
    "    \"batch_6719c34183d881909d84f283a4ea3e55\",\n",
    "    \"batch_6719c348e3488190b99ee5a11a5452f0\"\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for batch_id in completed_batch_ids:\n",
    "    results = get_completed_batch_results(batch_id)\n",
    "    all_results.extend(results)\n",
    "    log_info(f\"Retrieved {len(results)} results from batch {batch_id}\")\n",
    "\n",
    "# Display a sample of the results\n",
    "print(\"\\nSample of completed results:\")\n",
    "for result in all_results[:5]:  # Display first 5 results\n",
    "    print(f\"\\nCustom ID: {result['custom_id']}\")\n",
    "    response_body = result['response']['body']\n",
    "    if isinstance(response_body, str):\n",
    "        response_body = json.loads(response_body)\n",
    "    print(f\"Response: {json.dumps(response_body, indent=2)}\")\n",
    "\n",
    "# Save all results to a file\n",
    "with open('completed_results.json', 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "log_info(f\"Total results retrieved: {len(all_results)}\")\n",
    "log_info(\"All results saved to completed_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Food Deals:\n",
      "\n",
      "1. Turkey Breast\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/885001499\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $1.79/lb\n",
      "   Deal Score: 5/5\n",
      "   Meal Prep Score: 5/5\n",
      "   Recommendation: Buy now and stock your freezer for later meals!\n",
      "   In Season: Yes\n",
      "\n",
      "2. Large Avocados\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/885001507\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $0.99/ea\n",
      "   Deal Score: 5/5\n",
      "   Meal Prep Score: 5/5\n",
      "   Recommendation: Buy as many as you can use before they spoil!\n",
      "   In Season: Yes\n",
      "\n",
      "3. Boneless Pork Sirloin Roast\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/885001383\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $1.29/lb\n",
      "   Deal Score: 5/5\n",
      "   Meal Prep Score: 5/5\n",
      "   Recommendation: This is a great price for pork. Buy and freeze for future meals!\n",
      "   In Season: Yes\n",
      "\n",
      "4. Campbell's Condensed Soup, 10.5-11.25 oz, StarKist Tuna or Tuna Creations, 2.6-3 oz, Smart Bowls, 4.5 oz, Ro-Tel Diced Tomatoes, 10 oz, La Banderita Soft Taco Flour Tortillas, 10 ct, Kraft Barbecue Sauce, 18 oz, Hunt's Pasta Sauce, 24 oz\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/883148788\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $0.09/oz\n",
      "   Deal Score: 5/5\n",
      "   Meal Prep Score: 4/5\n",
      "   Recommendation: Buy bulk and fill your pantry; great for quick meals!\n",
      "   In Season: Yes\n",
      "\n",
      "5. Progresso Soup\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/885001475\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $0.07/oz\n",
      "   Deal Score: 5/5\n",
      "   Meal Prep Score: 4/5\n",
      "   Recommendation: Buy a lot and stock up for winter meals!\n",
      "   In Season: No\n",
      "\n",
      "6. Kroger Apple Cider\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/883149338\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $0.03/fl oz\n",
      "   Deal Score: 5/5\n",
      "   Meal Prep Score: 2/5\n",
      "   Recommendation: Buy if you enjoy seasonal beverages, especially for fall gatherings!\n",
      "   In Season: Yes\n",
      "\n",
      "7. Quaker Old Fashioned Oats 42 Oz\n",
      "   Store: Big Lots - Flyer (Flyer ID: 6899316)\n",
      "   Flipp URL: https://flipp.com/en-us/item/884971371\n",
      "   Date Range: 20241021-20241027\n",
      "   Price: $0.12/oz\n",
      "   Deal Score: 4/5\n",
      "   Meal Prep Score: 5/5\n",
      "   Recommendation: Buy if you need it soon\n",
      "   In Season: Yes\n",
      "\n",
      "8. Jalapeños\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/883152780\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $0.99/lb\n",
      "   Deal Score: 4/5\n",
      "   Meal Prep Score: 5/5\n",
      "   Recommendation: Buy if you like spicy food or enjoy adding flavor to dishes!\n",
      "   In Season: Yes\n",
      "\n",
      "9. Boneless Beef London Broil or Rump Roast\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/883150499\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $6.99/lb\n",
      "   Deal Score: 4/5\n",
      "   Meal Prep Score: 5/5\n",
      "   Recommendation: Buy if you need it soon\n",
      "   In Season: Yes\n",
      "\n",
      "10. Red, Green or Black Seedless Grapes\n",
      "   Store: Smiths - Weekly Ad (Flyer ID: 6883659)\n",
      "   Flipp URL: https://flipp.com/en-us/item/885001401\n",
      "   Date Range: 20241023-20241029\n",
      "   Price: $0.88/lb\n",
      "   Deal Score: 4/5\n",
      "   Meal Prep Score: 5/5\n",
      "   Recommendation: Buy bulk for snacking or salads!\n",
      "   In Season: Yes\n",
      "\n",
      "Total food deals found: 205\n",
      "Sorted food deals saved to sorted_food_deals.json\n"
     ]
    }
   ],
   "source": [
    "# Cell to process and sort food deals, including item name and Flipp URL\n",
    "\n",
    "import json\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_response(response):\n",
    "    if isinstance(response['body'], str):\n",
    "        body = json.loads(response['body'])\n",
    "    else:\n",
    "        body = response['body']\n",
    "    \n",
    "    if isinstance(body['choices'][0]['message']['content'], str):\n",
    "        content = json.loads(body['choices'][0]['message']['content'])\n",
    "    else:\n",
    "        content = body['choices'][0]['message']['content']\n",
    "    \n",
    "    return content\n",
    "\n",
    "def extract_ad_info(custom_id):\n",
    "    parts = custom_id.split('|')\n",
    "    flyer_filename = parts[0]\n",
    "    item_id = parts[1]  # This is the individual advertisement ID\n",
    "    flyer_parts = flyer_filename.split('_')\n",
    "    store = flyer_parts[0]\n",
    "    ad_type = flyer_parts[1]\n",
    "    date_range = flyer_parts[2]\n",
    "    flyer_id = flyer_parts[3].split('.')[0]\n",
    "    return {\n",
    "        'store': store,\n",
    "        'ad_type': ad_type,\n",
    "        'date_range': date_range,\n",
    "        'flyer_id': flyer_id,\n",
    "        'item_id': item_id,\n",
    "        'flyer_filename': flyer_filename\n",
    "    }\n",
    "\n",
    "# Load the completed results\n",
    "with open('completed_results.json', 'r') as f:\n",
    "    all_results = json.load(f)\n",
    "\n",
    "# Process and filter food deals\n",
    "food_deals = []\n",
    "unlabeled_dir = Path('flyer_data')\n",
    "\n",
    "for result in all_results:\n",
    "    content = parse_response(result['response'])\n",
    "    \n",
    "    # Check if it's a food item (meal_prep_score > 1)\n",
    "    if content['meal_prep_score'] > 1:\n",
    "        ad_info = extract_ad_info(result['custom_id'])\n",
    "        \n",
    "        # Load the original flyer data to get the item name\n",
    "        with open(unlabeled_dir / ad_info['flyer_filename'], 'r') as f:\n",
    "            flyer_data = json.load(f)\n",
    "        \n",
    "        # Find the item in the flyer data\n",
    "        item = next((item for item in flyer_data['items'] if str(item['id']) == ad_info['item_id']), None)\n",
    "        item_name = item['name'] if item else \"Unknown Item\"\n",
    "        \n",
    "        deal = {\n",
    "            'store': ad_info['store'],\n",
    "            'ad_type': ad_info['ad_type'],\n",
    "            'date_range': ad_info['date_range'],\n",
    "            'flyer_id': ad_info['flyer_id'],\n",
    "            'item_id': ad_info['item_id'],\n",
    "            'item_name': item_name,\n",
    "            'flipp_url': f\"https://flipp.com/en-us/item/{ad_info['item_id']}\",\n",
    "            'price_per_unit': content['price_per_unit'],\n",
    "            'deal_score': content['deal_score'],\n",
    "            'meal_prep_score': content['meal_prep_score'],\n",
    "            'user_recommendation': content['user_recommendation'],\n",
    "            'in_season': content['in_season']\n",
    "        }\n",
    "        food_deals.append(deal)\n",
    "\n",
    "# Sort food deals by deal_score and meal_prep_score\n",
    "sorted_food_deals = sorted(food_deals, key=itemgetter('deal_score', 'meal_prep_score'), reverse=True)\n",
    "\n",
    "# Display top 10 food deals\n",
    "print(\"Top 10 Food Deals:\")\n",
    "for i, deal in enumerate(sorted_food_deals[:10], 1):\n",
    "    print(f\"\\n{i}. {deal['item_name']}\")\n",
    "    print(f\"   Store: {deal['store']} - {deal['ad_type']} (Flyer ID: {deal['flyer_id']})\")\n",
    "    print(f\"   Flipp URL: {deal['flipp_url']}\")\n",
    "    print(f\"   Date Range: {deal['date_range']}\")\n",
    "    print(f\"   Price: {deal['price_per_unit']}\")\n",
    "    print(f\"   Deal Score: {deal['deal_score']}/5\")\n",
    "    print(f\"   Meal Prep Score: {deal['meal_prep_score']}/5\")\n",
    "    print(f\"   Recommendation: {deal['user_recommendation']}\")\n",
    "    print(f\"   In Season: {'Yes' if deal['in_season'] else 'No'}\")\n",
    "\n",
    "# Save sorted food deals to a file\n",
    "with open('sorted_food_deals.json', 'w') as f:\n",
    "    json.dump(sorted_food_deals, f, indent=2)\n",
    "\n",
    "print(f\"\\nTotal food deals found: {len(sorted_food_deals)}\")\n",
    "print(\"Sorted food deals saved to sorted_food_deals.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
