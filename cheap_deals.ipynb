{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "#pip install openai tqdm python-dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%b %d, %Y\")\n",
    "\n",
    "# Set up directories\n",
    "unlabeled_dir = Path('flyer_data')\n",
    "labeled_dir = Path('labeled_flyer_data')\n",
    "batch_dir = Path('batch_files')\n",
    "labeled_dir.mkdir(exist_ok=True)\n",
    "batch_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def log_info(message):\n",
    "    \"\"\"Log information to a file and print to console.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open('batch_processing_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {message}\\n\")\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to retrieve and cancel all current batch tasks\n",
    "\n",
    "def cancel_all_batches():\n",
    "    # Retrieve all batches\n",
    "    batches = client.batches.list()\n",
    "    # get the status of each batch\n",
    "    batch_statuses = [client.batches.retrieve(batch.id) for batch in batches.data]\n",
    "    # filter out the completed batches\n",
    "    active_batches = [batch for batch in batch_statuses if batch.status != \"completed\" and batch.status != \"failed\"]\n",
    "    \n",
    "    log_info(f\"Found {len(batches.data)} batches.\")\n",
    "    \n",
    "    # Cancel each batch\n",
    "    for batch in tqdm(active_batches, desc=\"Cancelling batches\"):\n",
    "        try:\n",
    "            client.batches.cancel(batch.id)\n",
    "            log_info(f\"Cancelled batch {batch.id}\")\n",
    "        except Exception as e:\n",
    "            log_info(f\"Error cancelling batch {batch.id}: {str(e)}\")\n",
    "    \n",
    "    log_info(\"Finished cancelling batches.\")\n",
    "\n",
    "# Run the function to cancel all batches\n",
    "cancel_all_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Your goal is to help shoppers find the best deals. You will be given an image of a product ad and its price.\n",
    "Calculate the price per unit and recommend what the user should do with the item. If at all possible,\n",
    "get the unit as a weight or volume. Especially for food items, this is usually the best way to compare deals.\n",
    "\"\"\"\n",
    "\n",
    "def prepare_deal_input(item, flyer_filename):\n",
    "    price = float(item['price'])\n",
    "    return {\n",
    "        \"custom_id\": f\"{flyer_filename}|{item['id']}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"Today is {current_date}. Evaluate {item['name']} priced at ${price:.2f}.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": item['cutout_image_url']}}\n",
    "                ]}\n",
    "            ],\n",
    "            \"max_tokens\": 100,\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"deal_schema\",\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"price_per_unit\": {\n",
    "                                \"description\": \"Formatted as $X.XX/unit, where unit is one of: lb, oz, g, kg, gal, qt, pt, fl oz, ea.\",\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            \"user_recommendation\": {\n",
    "                                \"description\": \"Tell the user what to do with this item so they can save money. For example, 'Buy bulk and fill your freezer!', 'Wait for a better deal', 'Buy if you need it soon', 'This deal is so good you should buy and resell it!'\",\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            \"deal_score\": {\n",
    "                                \"description\": \"A score from 1 to 5 indicating how good the deal is. 1 is worse than average, 2 is around the expected price, and 5 is that rare smoking unicorn deal.\",\n",
    "                                \"type\": \"integer\",\n",
    "                                \"minimum\": 1,\n",
    "                                \"maximum\": 5\n",
    "                            },\n",
    "                            \"meal_prep_score\": {\n",
    "                                \"description\": \"A score from 1 to 5 indicating how good the deal is for meal-prepping. 1 is anything that isn't a food item, 2 is food that isn't very nutritious (soft drinks, candy, chips), 3 is high quality sweets (pastries, ice cream, etc.), 4 is good canned or frozen food, and 5 is fresh produce, meat, dairy, or other high quality food.\",\n",
    "                                \"type\": \"integer\",\n",
    "                                \"minimum\": 1,\n",
    "                                \"maximum\": 5\n",
    "                            },\n",
    "                            \"in_season\": {\n",
    "                                \"description\": \"true if the item is in season, false otherwise.\",\n",
    "                                \"type\": \"boolean\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 244.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 63 unlabeled flyers\n",
      "Prepared 4360 items for batch processing\n",
      "Estimated total tokens: 39420013\n",
      "  - Text tokens: 2360013\n",
      "  - Image tokens: 37060000\n",
      "Estimated number of batches: 22\n",
      "Estimated total cost: $5.87\n",
      "Flyers to process saved: flyers_to_process.json\n",
      "Batch input saved: batch_input.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load flyer data, prepare batch input, and estimate cost\n",
    "\n",
    "def estimate_tokens(text, has_image=True):\n",
    "    \"\"\"Estimate the number of tokens in the given text, plus image tokens if applicable.\"\"\"\n",
    "    text_tokens = len(text) // 4  # Using the heuristic that 1 token ~= 4 chars in English\n",
    "    image_tokens = 8500 if has_image else 0  # Add 8500 tokens for each image\n",
    "    return text_tokens, image_tokens\n",
    "\n",
    "def estimate_cost(text_tokens, image_tokens, max_output_tokens=100):\n",
    "    \"\"\"Estimate the cost based on input tokens, image tokens, and output tokens.\"\"\"\n",
    "    image_cost = (image_tokens / 1_000_000) * 0.15\n",
    "    input_text_cost = (text_tokens / 1_000_000) * 0.075\n",
    "    output_cost = (max_output_tokens / 1_000_000) * 0.300\n",
    "    return image_cost + input_text_cost + output_cost\n",
    "\n",
    "batch_input = []\n",
    "flyers_to_process = []\n",
    "total_text_tokens = 0\n",
    "total_image_tokens = 0\n",
    "total_cost = 0\n",
    "MAX_TOKENS_PER_BATCH = 1_800_000\n",
    "\n",
    "for flyer_file in tqdm(list(unlabeled_dir.glob('*.json'))):\n",
    "    with open(flyer_file, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    \n",
    "    flyers_to_process.append(flyer_file.name)\n",
    "    \n",
    "    for item in flyer_data['items']:\n",
    "        deal_input = prepare_deal_input(item, flyer_file.name)\n",
    "        batch_input.append(deal_input)\n",
    "        \n",
    "        text_tokens, image_tokens = estimate_tokens(json.dumps(deal_input))\n",
    "        total_text_tokens += text_tokens\n",
    "        total_image_tokens += image_tokens\n",
    "        total_cost += estimate_cost(text_tokens, image_tokens)\n",
    "\n",
    "total_tokens = total_text_tokens + total_image_tokens\n",
    "num_batches = ceil(total_tokens / MAX_TOKENS_PER_BATCH)\n",
    "\n",
    "log_info(f\"Loaded {len(flyers_to_process)} unlabeled flyers\")\n",
    "log_info(f\"Prepared {len(batch_input)} items for batch processing\")\n",
    "log_info(f\"Estimated total tokens: {total_tokens}\")\n",
    "log_info(f\"  - Text tokens: {total_text_tokens}\")\n",
    "log_info(f\"  - Image tokens: {total_image_tokens}\")\n",
    "log_info(f\"Estimated number of batches: {num_batches}\")\n",
    "log_info(f\"Estimated total cost: ${total_cost:.2f}\")\n",
    "\n",
    "# Save flyers to process for later use\n",
    "with open('flyers_to_process.json', 'w') as f:\n",
    "    json.dump(flyers_to_process, f)\n",
    "\n",
    "log_info(\"Flyers to process saved: flyers_to_process.json\")\n",
    "\n",
    "# Save batch input for later use\n",
    "with open('batch_input.json', 'w') as f:\n",
    "    json.dump(batch_input, f)\n",
    "\n",
    "log_info(\"Batch input saved: batch_input.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 22 batch files in batch_files\n"
     ]
    }
   ],
   "source": [
    "MAX_ITEMS_PER_BATCH = 200  # Adjust this value as needed\n",
    "\n",
    "batches = [batch_input[i:i + MAX_ITEMS_PER_BATCH] for i in range(0, len(batch_input), MAX_ITEMS_PER_BATCH)]\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    batch_filename = batch_dir / f'batch_input_{i}.jsonl'\n",
    "    with open(batch_filename, 'w') as f:\n",
    "        for item in batch:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "log_info(f\"Created {len(batches)} batch files in {batch_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch group 1 of 5\n",
      "Uploaded batch input file batch_input_0.jsonl with ID: file-U7KVqb41MQmS94XQYobRd4CT\n",
      "Created batch for batch_input_0.jsonl with ID: batch_6719d28f9f708190ab518c5026079ab8\n",
      "Uploaded batch input file batch_input_1.jsonl with ID: file-PrFTQZyAxIzpcXp2yvE03yMk\n",
      "Created batch for batch_input_1.jsonl with ID: batch_6719d290e1c08190adf240b10e0e6c30\n",
      "Uploaded batch input file batch_input_10.jsonl with ID: file-qrEYGCMj8S3EniQjpzK5hrOo\n",
      "Created batch for batch_input_10.jsonl with ID: batch_6719d2927dd881908d9da8e5e8a3a6ea\n",
      "Uploaded batch input file batch_input_11.jsonl with ID: file-WmvfZD885m1LceyoZ3jjVnoc\n",
      "Created batch for batch_input_11.jsonl with ID: batch_6719d293926c819099122729ed75ae8a\n",
      "Uploaded batch input file batch_input_12.jsonl with ID: file-r9XH24aEvHplHR01HL7Vv8ng\n",
      "Created batch for batch_input_12.jsonl with ID: batch_6719d294b9088190affd25e35ff9a4f7\n",
      "Waiting for 5 batches to complete...\n",
      "Batch batch_6719d2927dd881908d9da8e5e8a3a6ea completed and processed.\n",
      "Waiting for 4 batches to complete...\n",
      "Waiting for 4 batches to complete...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_CONCURRENT_BATCHES = 5\n",
    "BATCH_CHECK_INTERVAL = 60\n",
    "\n",
    "def process_batch_group(batch_files):\n",
    "    batch_ids = []\n",
    "    for batch_file in batch_files:\n",
    "        batch_input_file = client.files.create(\n",
    "            file=open(batch_file, \"rb\"),\n",
    "            purpose=\"batch\"\n",
    "        )\n",
    "\n",
    "        log_info(f\"Uploaded batch input file {batch_file.name} with ID: {batch_input_file.id}\")\n",
    "\n",
    "        batch = client.batches.create(\n",
    "            input_file_id=batch_input_file.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "                \"description\": f\"Cheap deals analysis batch {batch_file.name}\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        batch_ids.append(batch.id)\n",
    "        log_info(f\"Created batch for {batch_file.name} with ID: {batch.id}\")\n",
    "    \n",
    "    return batch_ids\n",
    "\n",
    "def wait_for_batches(batch_ids):\n",
    "    active_batches = batch_ids.copy()\n",
    "    all_results = []\n",
    "    \n",
    "    while active_batches:\n",
    "        for batch_id in active_batches[:]:\n",
    "            batch_status = client.batches.retrieve(batch_id)\n",
    "            \n",
    "            if batch_status.status == \"completed\":\n",
    "                output_file_content = client.files.content(batch_status.output_file_id)\n",
    "                output_text = output_file_content.read().decode('utf-8')\n",
    "                batch_results = [json.loads(line) for line in output_text.strip().split('\\n')]\n",
    "                all_results.extend(batch_results)\n",
    "                active_batches.remove(batch_id)\n",
    "                log_info(f\"Batch {batch_id} completed and processed.\")\n",
    "            elif batch_status.status == \"failed\":\n",
    "                log_info(f\"Batch {batch_id} failed. Error: {batch_status.errors}\")\n",
    "                active_batches.remove(batch_id)\n",
    "        \n",
    "        if active_batches:\n",
    "            log_info(f\"Waiting for {len(active_batches)} batches to complete...\")\n",
    "            time.sleep(BATCH_CHECK_INTERVAL)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Process batches in groups\n",
    "all_results = []\n",
    "batch_files = list(batch_dir.glob('batch_input_*.jsonl'))\n",
    "for i in range(0, len(batch_files), MAX_CONCURRENT_BATCHES):\n",
    "    batch_group = batch_files[i:i+MAX_CONCURRENT_BATCHES]\n",
    "    log_info(f\"Processing batch group {i//MAX_CONCURRENT_BATCHES + 1} of {ceil(len(batch_files)/MAX_CONCURRENT_BATCHES)}\")\n",
    "    \n",
    "    batch_ids = process_batch_group(batch_group)\n",
    "    group_results = wait_for_batches(batch_ids)\n",
    "    all_results.extend(group_results)\n",
    "    \n",
    "    log_info(f\"Completed batch group {i//MAX_CONCURRENT_BATCHES + 1}. Total results so far: {len(all_results)}\")\n",
    "\n",
    "# Save all results\n",
    "with open('completed_results.json', 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "log_info(f\"All results saved to completed_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_response(response):\n",
    "    if isinstance(response['body'], str):\n",
    "        body = json.loads(response['body'])\n",
    "    else:\n",
    "        body = response['body']\n",
    "    \n",
    "    if isinstance(body['choices'][0]['message']['content'], str):\n",
    "        content = json.loads(body['choices'][0]['message']['content'])\n",
    "    else:\n",
    "        content = body['choices'][0]['message']['content']\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Group results by flyer\n",
    "flyer_results = {}\n",
    "for result in all_results:\n",
    "    flyer_filename, item_id = result['custom_id'].split('|')\n",
    "    if flyer_filename not in flyer_results:\n",
    "        flyer_results[flyer_filename] = []\n",
    "    flyer_results[flyer_filename].append((item_id, parse_response(result['response'])))\n",
    "\n",
    "# Update flyers with results and save labeled versions\n",
    "with open('flyers_to_process.json', 'r') as f:\n",
    "    flyers_to_process = json.load(f)\n",
    "\n",
    "for flyer_filename in flyers_to_process:\n",
    "    with open(unlabeled_dir / flyer_filename, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    \n",
    "    for item in flyer_data['items']:\n",
    "        item_results = next((r for r in flyer_results[flyer_filename] if r[0] == str(item['id'])), None)\n",
    "        if item_results:\n",
    "            item['deal_analysis'] = item_results[1]\n",
    "    \n",
    "    # Save labeled flyer\n",
    "    labeled_file = labeled_dir / flyer_filename\n",
    "    with open(labeled_file, 'w') as f:\n",
    "        json.dump(flyer_data, f, indent=2)\n",
    "\n",
    "log_info(f\"Processed {len(all_results)} results and saved labeled flyers to {labeled_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.remove('flyers_to_process.json')\n",
    "for batch_file in batch_dir.glob('batch_input_*.jsonl'):\n",
    "    os.remove(batch_file)\n",
    "log_info(\"Cleaned up temporary files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled_flyers = list(labeled_dir.glob('*.json'))\n",
    "if labeled_flyers:\n",
    "    log_info(\"\\nSample of labeled items:\")\n",
    "    sample_flyer = labeled_flyers[0]\n",
    "    log_info(f\"Flyer: {sample_flyer.name}\")\n",
    "    with open(sample_flyer, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    for item in flyer_data['items'][:5]:\n",
    "        log_info(json.dumps(item, indent=2))\n",
    "        log_info(\"\")\n",
    "else:\n",
    "    log_info(\"No labeled flyers found. Please check if the processing completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
