{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "#pip install openai tqdm python-dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime(\"%b %d, %Y\")\n",
    "\n",
    "# Set up directories\n",
    "unlabeled_dir = Path('flyer_data')\n",
    "labeled_dir = Path('labeled_flyer_data')\n",
    "batch_dir = Path('batch_files')\n",
    "labeled_dir.mkdir(exist_ok=True)\n",
    "batch_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def log_info(message):\n",
    "    \"\"\"Log information to a file and print to console.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open('batch_processing_log.txt', 'a') as log_file:\n",
    "        log_file.write(f\"{timestamp} - {message}\\n\")\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Batch](data=[Batch(id='batch_671ab00ed6908190be09a2f166b902df', completion_window='24h', created_at=1729802254, endpoint='/v1/chat/completions', input_file_id='file-OpoIJ3CyFYmJHs3cqnuSl1qg', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1729802270, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1729888654, failed_at=None, finalizing_at=None, in_progress_at=1729802255, metadata={'description': 'Cheap deals analysis batch batch_input_2.jsonl'}, output_file_id=None, request_counts=BatchRequestCounts(completed=119, failed=0, total=200)), Batch(id='batch_671ab00dc87c8190b15ee50013905e3a', completion_window='24h', created_at=1729802253, endpoint='/v1/chat/completions', input_file_id='file-2j20NHILTyHfmEJnR6lZ5e8e', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1729802270, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1729888653, failed_at=None, finalizing_at=None, in_progress_at=1729802254, metadata={'description': 'Cheap deals analysis batch batch_input_0.jsonl'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=200)), Batch(id='batch_671ab00ce63c8190a9d7d0eb2a69300a', completion_window='24h', created_at=1729802253, endpoint='/v1/chat/completions', input_file_id='file-H2aBqZW14r12r0gN1gO1zGaQ', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1729802271, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1729888653, failed_at=None, finalizing_at=None, in_progress_at=1729802253, metadata={'description': 'Cheap deals analysis batch batch_input_5.jsonl'}, output_file_id=None, request_counts=BatchRequestCounts(completed=138, failed=0, total=200)), Batch(id='batch_671ab00c33cc8190925894c6e0f3fe8c', completion_window='24h', created_at=1729802252, endpoint='/v1/chat/completions', input_file_id='file-6pxUaXkOsf8LFBwcV78pBVim', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1729802271, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1729888652, failed_at=None, finalizing_at=None, in_progress_at=1729802252, metadata={'description': 'Cheap deals analysis batch batch_input_4.jsonl'}, output_file_id=None, request_counts=BatchRequestCounts(completed=142, failed=0, total=200)), Batch(id='batch_671ab00b4fb88190944f6d37e593daa0', completion_window='24h', created_at=1729802251, endpoint='/v1/chat/completions', input_file_id='file-h4QxVhPMPmK4gjxUlWDGPtcW', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1729802271, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1729888651, failed_at=None, finalizing_at=None, in_progress_at=1729802251, metadata={'description': 'Cheap deals analysis batch batch_input_7.jsonl'}, output_file_id=None, request_counts=BatchRequestCounts(completed=151, failed=0, total=200)), Batch(id='batch_671aae29e07081908df5b50af842abe2', completion_window='24h', created_at=1729801770, endpoint='/v1/chat/completions', input_file_id='file-T1GN5T3xV6eNZ2huuv3Ya7ks', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1729802136, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1729888170, failed_at=None, finalizing_at=None, in_progress_at=1729801770, metadata={'description': 'Cheap deals analysis batch batch_input_4.jsonl'}, output_file_id=None, request_counts=BatchRequestCounts(completed=199, failed=0, total=200)), Batch(id='batch_671aae290a4c8190a5d01ca3a1ea73a9', completion_window='24h', created_at=1729801769, endpoint='/v1/chat/completions', input_file_id='file-F51rSieP7QXA4jMEtyr5OjDM', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729801814, error_file_id=None, errors=None, expired_at=None, expires_at=1729888169, failed_at=None, finalizing_at=1729801801, in_progress_at=1729801769, metadata={'description': 'Cheap deals analysis batch batch_input_9.jsonl'}, output_file_id='file-zjziafEHAnD0ppiWx81eLkxO', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_671aae278cf48190bd18751a633cd5b3', completion_window='24h', created_at=1729801767, endpoint='/v1/chat/completions', input_file_id='file-aPvQ11i10cKBI5PaFnQurNrO', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729801869, error_file_id=None, errors=None, expired_at=None, expires_at=1729888167, failed_at=None, finalizing_at=1729801854, in_progress_at=1729801768, metadata={'description': 'Cheap deals analysis batch batch_input_7.jsonl'}, output_file_id='file-et9kXfc0onpx1brRTsSG54TO', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_671aae26636c81908443b1a72706b5a3', completion_window='24h', created_at=1729801766, endpoint='/v1/chat/completions', input_file_id='file-bPYIdE6NhouvKQbJlTpEIdZH', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729801811, error_file_id=None, errors=None, expired_at=None, expires_at=1729888166, failed_at=None, finalizing_at=1729801797, in_progress_at=1729801766, metadata={'description': 'Cheap deals analysis batch batch_input_10.jsonl'}, output_file_id='file-wfAORpYijSn1sD3Q4GgMX7Nk', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_671aae25062c81909259d9d77eb00b7e', completion_window='24h', created_at=1729801765, endpoint='/v1/chat/completions', input_file_id='file-qNRIvrtktEF3xNocQaYPfwok', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729801933, error_file_id=None, errors=None, expired_at=None, expires_at=1729888165, failed_at=None, finalizing_at=1729801920, in_progress_at=1729801765, metadata={'description': 'Cheap deals analysis batch batch_input_22.jsonl'}, output_file_id='file-ho4HYBfe8wmjhV9WnLmeGtnj', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_671aaa52b9208190b8d08252331adfe4', completion_window='24h', created_at=1729800786, endpoint='/v1/chat/completions', input_file_id='file-c47EZnLZFoSDJm75fj9GOg1g', object='batch', status='cancelled', cancelled_at=1729801476, cancelling_at=1729800826, completed_at=None, error_file_id='file-DpKgK1NfcfPGlmdGuWGw3KTF', errors=None, expired_at=None, expires_at=1729887186, failed_at=None, finalizing_at=None, in_progress_at=1729800787, metadata={'description': 'Cheap deals analysis batch batch_input_4.jsonl'}, output_file_id='file-mvtdQ6IETo7UR7NbVWNAjXgK', request_counts=BatchRequestCounts(completed=197, failed=0, total=200)), Batch(id='batch_671aaa516864819090b63df03f27caf9', completion_window='24h', created_at=1729800785, endpoint='/v1/chat/completions', input_file_id='file-bwMWinYTvjNPM2SRVKFsOWW4', object='batch', status='cancelled', cancelled_at=1729800848, cancelling_at=1729800827, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1729887185, failed_at=None, finalizing_at=None, in_progress_at=1729800785, metadata={'description': 'Cheap deals analysis batch batch_input_9.jsonl'}, output_file_id='file-Wt4tYX24ztxffNTlI01GOzHu', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_671aaa50655c8190886cda9a15d6d08d', completion_window='24h', created_at=1729800784, endpoint='/v1/chat/completions', input_file_id='file-zE0Ztt731UJ7Maw2YriFHJmo', object='batch', status='cancelled', cancelled_at=1729801476, cancelling_at=1729800827, completed_at=None, error_file_id='file-Mj0acMRkxJd42Clm8DqmPbQQ', errors=None, expired_at=None, expires_at=1729887184, failed_at=None, finalizing_at=None, in_progress_at=1729800784, metadata={'description': 'Cheap deals analysis batch batch_input_7.jsonl'}, output_file_id='file-ViSCaxMoBGzScCbUNoEYXe4n', request_counts=BatchRequestCounts(completed=199, failed=0, total=200)), Batch(id='batch_671aaa4f0ca88190ba628449a3495860', completion_window='24h', created_at=1729800783, endpoint='/v1/chat/completions', input_file_id='file-w8bYXrvLnHt8qFuBHFPC0kom', object='batch', status='cancelled', cancelled_at=1729800860, cancelling_at=1729800828, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1729887183, failed_at=None, finalizing_at=None, in_progress_at=1729800783, metadata={'description': 'Cheap deals analysis batch batch_input_10.jsonl'}, output_file_id='file-9cHgRHDtYtiIDUPh2crkZIol', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_671aaa4e1d2481909c1d549c620869a5', completion_window='24h', created_at=1729800782, endpoint='/v1/chat/completions', input_file_id='file-iLADtywK5y46sjm41YgP6ksN', object='batch', status='cancelled', cancelled_at=1729801477, cancelling_at=1729800828, completed_at=None, error_file_id='file-RhUZBEVOYpNEYvCNjBCzStK0', errors=None, expired_at=None, expires_at=1729887182, failed_at=None, finalizing_at=None, in_progress_at=1729800782, metadata={'description': 'Cheap deals analysis batch batch_input_22.jsonl'}, output_file_id='file-1Qv0GGtaYD2ijZb3aGL7NJFI', request_counts=BatchRequestCounts(completed=199, failed=0, total=200)), Batch(id='batch_6719de9f33c881908c2b34e9b67f8300', completion_window='24h', created_at=1729748639, endpoint='/v1/chat/completions', input_file_id='file-mzvNp9xMNmYfx1xTwnF7wDur', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729748681, error_file_id='file-S5fVXmiEiWt4voMQ1iMdQJ8G', errors=None, expired_at=None, expires_at=1729835039, failed_at=None, finalizing_at=1729748669, in_progress_at=1729748639, metadata={'description': 'Cheap deals analysis batch batch_input_16.jsonl'}, output_file_id='file-sXtPyzYTAILbYXD59CgnjUYD', request_counts=BatchRequestCounts(completed=199, failed=1, total=200)), Batch(id='batch_6719de9e7544819089d6e0b43aa4b40e', completion_window='24h', created_at=1729748638, endpoint='/v1/chat/completions', input_file_id='file-qov47LT5ZZrQR4IDGukuYRAH', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729748680, error_file_id=None, errors=None, expired_at=None, expires_at=1729835038, failed_at=None, finalizing_at=1729748666, in_progress_at=1729748638, metadata={'description': 'Cheap deals analysis batch batch_input_6.jsonl'}, output_file_id='file-GzCmUFxMzdmZQw2HTWTrJ15r', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_6719de9da1dc8190927ee2182fa3362a', completion_window='24h', created_at=1729748637, endpoint='/v1/chat/completions', input_file_id='file-uYzW3UisdjQrdSFYa1rvOQRV', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729748827, error_file_id=None, errors=None, expired_at=None, expires_at=1729835037, failed_at=None, finalizing_at=1729748814, in_progress_at=1729748638, metadata={'description': 'Cheap deals analysis batch batch_input_15.jsonl'}, output_file_id='file-Pj4xLVe5UcNaZT7jC8N6rtkU', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_6719de9c4720819096133a8be7ef45e3', completion_window='24h', created_at=1729748636, endpoint='/v1/chat/completions', input_file_id='file-Fa6eSWvTXeQtymR0slgkc3VT', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729749664, error_file_id=None, errors=None, expired_at=None, expires_at=1729835036, failed_at=None, finalizing_at=1729749649, in_progress_at=1729748636, metadata={'description': 'Cheap deals analysis batch batch_input_1.jsonl'}, output_file_id='file-VbfZi8dYaTp50ab6SIdqGZHs', request_counts=BatchRequestCounts(completed=200, failed=0, total=200)), Batch(id='batch_6719de9b45188190981a8a3ad18b0390', completion_window='24h', created_at=1729748635, endpoint='/v1/chat/completions', input_file_id='file-2hhOGpgGht7M2rXuykWFz7Sg', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1729749720, error_file_id=None, errors=None, expired_at=None, expires_at=1729835035, failed_at=None, finalizing_at=1729749705, in_progress_at=1729748635, metadata={'description': 'Cheap deals analysis batch batch_input_3.jsonl'}, output_file_id='file-yMlokDtWiLcW0IXbM9Ov4CCB', request_counts=BatchRequestCounts(completed=200, failed=0, total=200))], object='list', first_id='batch_671ab00ed6908190be09a2f166b902df', last_id='batch_6719de9b45188190981a8a3ad18b0390', has_more=True)\n",
      "Found 20 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancelling batches:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled batch batch_671ab00ed6908190be09a2f166b902df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancelling batches:  18%|█▊        | 2/11 [00:00<00:00,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled batch batch_671ab00dc87c8190b15ee50013905e3a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancelling batches:  45%|████▌     | 5/11 [00:00<00:00,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled batch batch_671ab00ce63c8190a9d7d0eb2a69300a\n",
      "Cancelled batch batch_671ab00c33cc8190925894c6e0f3fe8c\n",
      "Cancelled batch batch_671ab00b4fb88190944f6d37e593daa0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancelling batches:  64%|██████▎   | 7/11 [00:00<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled batch batch_671aae29e07081908df5b50af842abe2\n",
      "Cancelled batch batch_671aaa52b9208190b8d08252331adfe4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancelling batches:  82%|████████▏ | 9/11 [00:01<00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled batch batch_671aaa516864819090b63df03f27caf9\n",
      "Cancelled batch batch_671aaa50655c8190886cda9a15d6d08d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancelling batches:  91%|█████████ | 10/11 [00:01<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled batch batch_671aaa4f0ca88190ba628449a3495860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancelling batches: 100%|██████████| 11/11 [00:01<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancelled batch batch_671aaa4e1d2481909c1d549c620869a5\n",
      "Finished cancelling batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell to retrieve and cancel all current batch tasks\n",
    "\n",
    "def cancel_all_batches():\n",
    "    # Retrieve all batches\n",
    "    batches = client.batches.list()\n",
    "    print(batches)\n",
    "    # get the status of each batch\n",
    "    batch_statuses = [client.batches.retrieve(batch.id) for batch in batches.data]\n",
    "    # filter out the completed batches\n",
    "    active_batches = [batch for batch in batch_statuses if batch.status != \"completed\" and batch.status != \"failed\"]\n",
    "    \n",
    "    log_info(f\"Found {len(batches.data)} batches.\")\n",
    "    \n",
    "    # Cancel each batch\n",
    "    for batch in tqdm(active_batches, desc=\"Cancelling batches\"):\n",
    "        try:\n",
    "            client.batches.cancel(batch.id)\n",
    "            log_info(f\"Cancelled batch {batch.id}\")\n",
    "        except Exception as e:\n",
    "            log_info(f\"Error cancelling batch {batch.id}: {str(e)}\")\n",
    "    \n",
    "    log_info(\"Finished cancelling batches.\")\n",
    "\n",
    "# Run the function to cancel all batches\n",
    "cancel_all_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Your goal is to help shoppers find the best deals. You will be given an image of a product ad and its price.\n",
    "Calculate the price per unit and recommend what the user should do with the item. If at all possible,\n",
    "get the unit as a weight or volume. Especially for food items, this is usually the best way to compare deals.\n",
    "\"\"\"\n",
    "\n",
    "def prepare_deal_input(item, flyer_filename):\n",
    "    price = item.get('price')\n",
    "    price_text = f\"priced at ${float(price):.2f}\" if price else \"with no price listed\"\n",
    "    return {\n",
    "        \"custom_id\": f\"{flyer_filename}|{item['id']}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"Today is {current_date}. Evaluate {item['name']} {price_text}.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": item['cutout_image_url']}}\n",
    "                ]}\n",
    "            ],\n",
    "            \"max_tokens\": 100,\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"deal_schema\",\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"price_per_unit\": {\n",
    "                                \"description\": \"Formatted as $X.XX/unit, where unit is one of: lb, oz, g, kg, gal, qt, pt, fl oz, ea. If no price is available, use 'N/A'.\",\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            \"user_recommendation\": {\n",
    "                                \"description\": \"Tell the user what to do with this item so they can save money. For example, 'Buy bulk and fill your freezer!', 'Wait for a better deal', 'Buy if you need it soon', 'This deal is so good you should buy and resell it!'.\",\n",
    "                                \"type\": \"string\"\n",
    "                            },\n",
    "                            \"deal_score\": {\n",
    "                                \"description\": \"A score from 1 to 5 indicating how good the deal is. 1 is worse than average, 2 is around the expected price, and 5 is that rare smoking unicorn deal. If no price is available, use 0.\",\n",
    "                                \"type\": \"integer\",\n",
    "                                \"minimum\": 0,\n",
    "                                \"maximum\": 5\n",
    "                            },\n",
    "                            \"meal_prep_score\": {\n",
    "                                \"description\": \"A score from 1 to 5 indicating how good the deal is for meal-prepping. 1 is anything that isn't a food item, 2 is food that isn't very nutritious (soft drinks, candy, chips), 3 is high quality sweets (pastries, ice cream, etc.), 4 is good canned or frozen food, and 5 is fresh produce, meat, dairy, or other high quality food.\",\n",
    "                                \"type\": \"integer\",\n",
    "                                \"minimum\": 1,\n",
    "                                \"maximum\": 5\n",
    "                            },\n",
    "                            \"in_season\": {\n",
    "                                \"description\": \"true if the item is in season, false otherwise.\",\n",
    "                                \"type\": \"boolean\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"additionalProperties\": False\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 205287.43it/s]\n",
      "100%|██████████| 63/63 [00:00<00:00, 841.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 unlabeled flyers\n",
      "Prepared 1648 items for batch processing\n",
      "Estimated total tokens: 14944421\n",
      "  - Text tokens: 936421\n",
      "  - Image tokens: 14008000\n",
      "Estimated number of batches: 9\n",
      "Estimated total cost: $2.22\n",
      "Flyers to process saved: flyers_to_process.json\n",
      "Batch input saved: batch_input.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load flyer data, prepare batch input, and estimate cost\n",
    "def estimate_tokens(text, has_image=True):\n",
    "    \"\"\"Estimate the number of tokens in the given text, plus image tokens if applicable.\"\"\"\n",
    "    text_tokens = len(text) // 4  # Using the heuristic that 1 token ~= 4 chars in English\n",
    "    image_tokens = 8500 if has_image else 0  # Add 8500 tokens for each image\n",
    "    return text_tokens, image_tokens\n",
    "\n",
    "def estimate_cost(text_tokens, image_tokens, max_output_tokens=100):\n",
    "    \"\"\"Estimate the cost based on input tokens, image tokens, and output tokens.\"\"\"\n",
    "    image_cost = (image_tokens / 1_000_000) * 0.15\n",
    "    input_text_cost = (text_tokens / 1_000_000) * 0.075\n",
    "    output_cost = (max_output_tokens / 1_000_000) * 0.300\n",
    "    return image_cost + input_text_cost + output_cost\n",
    "\n",
    "batch_input = []\n",
    "flyers_to_process = []\n",
    "total_text_tokens = 0\n",
    "total_image_tokens = 0\n",
    "total_cost = 0\n",
    "MAX_TOKENS_PER_BATCH = 1_800_000\n",
    "\n",
    "labeled_flyer_ids = []\n",
    "for labeled_flyer_file in tqdm(list(labeled_dir.glob('*.json'))):\n",
    "    labeled_flyer_id = labeled_flyer_file.stem.split('_')[-1]\n",
    "    labeled_flyer_ids.append(labeled_flyer_id)\n",
    "\n",
    "for flyer_file in tqdm(list(unlabeled_dir.glob('*.json'))):\n",
    "    with open(flyer_file, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "        flyer_id = flyer_file.stem.split('_')[-1]\n",
    "    \n",
    "    if flyer_id not in labeled_flyer_ids:\n",
    "        flyers_to_process.append(flyer_file.name)\n",
    "    \n",
    "        for item in flyer_data['items']:\n",
    "            deal_input = prepare_deal_input(item, flyer_file.name)\n",
    "            batch_input.append(deal_input)\n",
    "            \n",
    "            text_tokens, image_tokens = estimate_tokens(json.dumps(deal_input))\n",
    "            total_text_tokens += text_tokens\n",
    "            total_image_tokens += image_tokens\n",
    "            total_cost += estimate_cost(text_tokens, image_tokens)\n",
    "\n",
    "total_tokens = total_text_tokens + total_image_tokens\n",
    "num_batches = ceil(total_tokens / MAX_TOKENS_PER_BATCH)\n",
    "\n",
    "log_info(f\"Loaded {len(flyers_to_process)} unlabeled flyers\")\n",
    "log_info(f\"Prepared {len(batch_input)} items for batch processing\")\n",
    "log_info(f\"Estimated total tokens: {total_tokens}\")\n",
    "log_info(f\"  - Text tokens: {total_text_tokens}\")\n",
    "log_info(f\"  - Image tokens: {total_image_tokens}\")\n",
    "log_info(f\"Estimated number of batches: {num_batches}\")\n",
    "log_info(f\"Estimated total cost: ${total_cost:.2f}\")\n",
    "\n",
    "# Save flyers to process for later use\n",
    "with open('flyers_to_process.json', 'w') as f:\n",
    "    json.dump(flyers_to_process, f)\n",
    "\n",
    "log_info(\"Flyers to process saved: flyers_to_process.json\")\n",
    "\n",
    "# Save batch input for later use\n",
    "with open('batch_input.json', 'w') as f:\n",
    "    json.dump(batch_input, f)\n",
    "\n",
    "log_info(\"Batch input saved: batch_input.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 9 batch files in batch_files\n"
     ]
    }
   ],
   "source": [
    "MAX_ITEMS_PER_BATCH = 200  # Adjust this value as needed\n",
    "\n",
    "batches = [batch_input[i:i + MAX_ITEMS_PER_BATCH] for i in range(0, len(batch_input), MAX_ITEMS_PER_BATCH)]\n",
    "\n",
    "# delete everything in the folder\n",
    "for file in batch_dir.glob('*'):\n",
    "    file.unlink()\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    batch_filename = batch_dir / f'batch_input_{i}.jsonl'\n",
    "    with open(batch_filename, 'w') as f:\n",
    "        for item in batch:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "log_info(f\"Created {len(batches)} batch files in {batch_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch group 1 of 2\n",
      "Uploaded batch input file batch_input_7.jsonl with ID: file-h4QxVhPMPmK4gjxUlWDGPtcW\n",
      "Created batch for batch_input_7.jsonl with ID: batch_671ab00b4fb88190944f6d37e593daa0\n",
      "Uploaded batch input file batch_input_4.jsonl with ID: file-6pxUaXkOsf8LFBwcV78pBVim\n",
      "Created batch for batch_input_4.jsonl with ID: batch_671ab00c33cc8190925894c6e0f3fe8c\n",
      "Uploaded batch input file batch_input_5.jsonl with ID: file-H2aBqZW14r12r0gN1gO1zGaQ\n",
      "Created batch for batch_input_5.jsonl with ID: batch_671ab00ce63c8190a9d7d0eb2a69300a\n",
      "Uploaded batch input file batch_input_0.jsonl with ID: file-2j20NHILTyHfmEJnR6lZ5e8e\n",
      "Created batch for batch_input_0.jsonl with ID: batch_671ab00dc87c8190b15ee50013905e3a\n",
      "Uploaded batch input file batch_input_2.jsonl with ID: file-OpoIJ3CyFYmJHs3cqnuSl1qg\n",
      "Created batch for batch_input_2.jsonl with ID: batch_671ab00ed6908190be09a2f166b902df\n",
      "Waiting for 5 batches to complete...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m log_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing batch group \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mMAX_CONCURRENT_BATCHES\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mceil(\u001b[38;5;28mlen\u001b[39m(batch_files)\u001b[38;5;241m/\u001b[39mMAX_CONCURRENT_BATCHES)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m batch_ids \u001b[38;5;241m=\u001b[39m process_batch_group(batch_group)\n\u001b[0;32m---> 61\u001b[0m group_results \u001b[38;5;241m=\u001b[39m \u001b[43mwait_for_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m all_results\u001b[38;5;241m.\u001b[39mextend(group_results)\n\u001b[1;32m     64\u001b[0m log_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted batch group \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mMAX_CONCURRENT_BATCHES\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Total results so far: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 49\u001b[0m, in \u001b[0;36mwait_for_batches\u001b[0;34m(batch_ids)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m active_batches:\n\u001b[1;32m     48\u001b[0m         log_info(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(active_batches)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches to complete...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBATCH_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_CONCURRENT_BATCHES = 5\n",
    "BATCH_CHECK_INTERVAL = 60\n",
    "\n",
    "def process_batch_group(batch_files):\n",
    "    batch_ids = []\n",
    "    for batch_file in batch_files:\n",
    "        batch_input_file = client.files.create(\n",
    "            file=open(batch_file, \"rb\"),\n",
    "            purpose=\"batch\"\n",
    "        )\n",
    "\n",
    "        log_info(f\"Uploaded batch input file {batch_file.name} with ID: {batch_input_file.id}\")\n",
    "\n",
    "        batch = client.batches.create(\n",
    "            input_file_id=batch_input_file.id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "                \"description\": f\"Cheap deals analysis batch {batch_file.name}\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        batch_ids.append(batch.id)\n",
    "        log_info(f\"Created batch for {batch_file.name} with ID: {batch.id}\")\n",
    "    \n",
    "    return batch_ids\n",
    "\n",
    "def wait_for_batches(batch_ids):\n",
    "    active_batches = batch_ids.copy()\n",
    "    all_results = []\n",
    "    \n",
    "    while active_batches:\n",
    "        for batch_id in active_batches[:]:\n",
    "            batch_status = client.batches.retrieve(batch_id)\n",
    "            \n",
    "            if batch_status.status == \"completed\":\n",
    "                output_file_content = client.files.content(batch_status.output_file_id)\n",
    "                output_text = output_file_content.read().decode('utf-8')\n",
    "                batch_results = [json.loads(line) for line in output_text.strip().split('\\n')]\n",
    "                all_results.extend(batch_results)\n",
    "                active_batches.remove(batch_id)\n",
    "                log_info(f\"Batch {batch_id} completed and processed.\")\n",
    "            elif batch_status.status == \"failed\":\n",
    "                log_info(f\"Batch {batch_id} failed. Error: {batch_status.errors}\")\n",
    "                active_batches.remove(batch_id)\n",
    "        \n",
    "        if active_batches:\n",
    "            log_info(f\"Waiting for {len(active_batches)} batches to complete...\")\n",
    "            time.sleep(BATCH_CHECK_INTERVAL)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Process batches in groups\n",
    "all_results = []\n",
    "batch_files = list(batch_dir.glob('batch_input_*.jsonl'))\n",
    "for i in range(0, len(batch_files), MAX_CONCURRENT_BATCHES):\n",
    "    batch_group = batch_files[i:i+MAX_CONCURRENT_BATCHES]\n",
    "    log_info(f\"Processing batch group {i//MAX_CONCURRENT_BATCHES + 1} of {ceil(len(batch_files)/MAX_CONCURRENT_BATCHES)}\")\n",
    "    \n",
    "    batch_ids = process_batch_group(batch_group)\n",
    "    group_results = wait_for_batches(batch_ids)\n",
    "    all_results.extend(group_results)\n",
    "    \n",
    "    log_info(f\"Completed batch group {i//MAX_CONCURRENT_BATCHES + 1}. Total results so far: {len(all_results)}\")\n",
    "\n",
    "# Save all results\n",
    "with open('completed_results.json', 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "log_info(f\"All results saved to completed_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_response(response):\n",
    "    if isinstance(response['body'], str):\n",
    "        body = json.loads(response['body'])\n",
    "    else:\n",
    "        body = response['body']\n",
    "    \n",
    "    if isinstance(body['choices'][0]['message']['content'], str):\n",
    "        content = json.loads(body['choices'][0]['message']['content'])\n",
    "    else:\n",
    "        content = body['choices'][0]['message']['content']\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Group results by flyer\n",
    "flyer_results = {}\n",
    "for result in all_results:\n",
    "    flyer_filename, item_id = result['custom_id'].split('|')\n",
    "    if flyer_filename not in flyer_results:\n",
    "        flyer_results[flyer_filename] = []\n",
    "    flyer_results[flyer_filename].append((item_id, parse_response(result['response'])))\n",
    "\n",
    "# Update flyers with results and save labeled versions\n",
    "with open('flyers_to_process.json', 'r') as f:\n",
    "    flyers_to_process = json.load(f)\n",
    "\n",
    "for flyer_filename in flyers_to_process:\n",
    "    with open(unlabeled_dir / flyer_filename, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    \n",
    "    for item in flyer_data['items']:\n",
    "        item_results = next((r for r in flyer_results[flyer_filename] if r[0] == str(item['id'])), None)\n",
    "        if item_results:\n",
    "            item['deal_analysis'] = item_results[1]\n",
    "    \n",
    "    # Save labeled flyer\n",
    "    labeled_file = labeled_dir / flyer_filename\n",
    "    with open(labeled_file, 'w') as f:\n",
    "        json.dump(flyer_data, f, indent=2)\n",
    "\n",
    "log_info(f\"Processed {len(all_results)} results and saved labeled flyers to {labeled_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.remove('flyers_to_process.json')\n",
    "for batch_file in batch_dir.glob('batch_input_*.jsonl'):\n",
    "    os.remove(batch_file)\n",
    "log_info(\"Cleaned up temporary files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labeled_flyers = list(labeled_dir.glob('*.json'))\n",
    "if labeled_flyers:\n",
    "    log_info(\"\\nSample of labeled items:\")\n",
    "    sample_flyer = labeled_flyers[0]\n",
    "    log_info(f\"Flyer: {sample_flyer.name}\")\n",
    "    with open(sample_flyer, 'r') as f:\n",
    "        flyer_data = json.load(f)\n",
    "    for item in flyer_data['items'][:5]:\n",
    "        log_info(json.dumps(item, indent=2))\n",
    "        log_info(\"\")\n",
    "else:\n",
    "    log_info(\"No labeled flyers found. Please check if the processing completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
